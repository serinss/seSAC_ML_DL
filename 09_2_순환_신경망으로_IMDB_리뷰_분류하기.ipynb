{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-2. 순환 신경망으로 IMDB 리뷰 분류하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdh1n9zRaOABamH1WgeIkj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serinss/seSAC_ML_DL_Class/blob/main/09_2_%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9C%BC%EB%A1%9C_IMDB_%EB%A6%AC%EB%B7%B0_%EB%B6%84%EB%A5%98%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FP0dyH3hMAgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d3ccd37-a34e-4cd7-e5ce-352b9522f48b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "tf.__version__: 2.8.0\n",
            "keras.__version__: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "%run my_init.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run my_init.py"
      ],
      "metadata": {
        "id": "C2C-DbOZMMLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d1b51b-4ad8-445e-9605-752651f5cc71"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tf.__version__: 2.8.0\n",
            "keras.__version__: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMDB 리뷰 데이터셋"
      ],
      "metadata": {
        "id": "tGLydo0TMNe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=500) #가장 빈도가 많은(높은) 단어로 어휘사전을 만든다\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "metadata": {
        "id": "dl_BiFQrMQVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447dba99-fe1d-48c5-9a13-7b2b396a31a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "(25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: 패딩\n",
        "# 1: 시작\n",
        "# 2: 어휘사전에 등록되어 있지 않은 단어\n",
        "\n",
        "print(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1cWaJG-umlm",
        "outputId": "c977060b-8c77-42a6-a6f9-f8e7269ac389"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 2, 2, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 2, 112, 50, 2, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 2, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 2, 38, 76, 15, 13, 2, 4, 22, 17, 2, 17, 12, 16, 2, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 2, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 2, 36, 71, 43, 2, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:20])\n",
        "\n",
        "# 1: 긍정\n",
        "# 2: 부정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_4sSIyDuraC",
        "outputId": "4467d008-9d3f-4051-8e1b-c865ef7da492"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#훈련 세트 준비"
      ],
      "metadata": {
        "id": "aa00_COyaX_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42) # 20% validation\n",
        "lengths = np.array([len(x) for x in X_train])\n",
        "print(np.mean(lengths), np.median(lengths))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYE9DTTUvBdA",
        "outputId": "99f8ce84-5803-40b8-9625-3fb9399d8a1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "239.00925 178.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(lengths)\n",
        "plt.xlabel('length')\n",
        "plt.ylabel('frequency')\n",
        "plt.show()\n",
        "\n",
        "# 치우처져 있다 -> 대부분의 문장이 길지 않은 정도임을 유추할 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gttimOU0vVm1",
        "outputId": "7a038e61-8491-4e5a-c82f-14cfaa4e3628"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#시퀀스 패딩\n",
        "변동폭 길이 -> 고정폭 길이"
      ],
      "metadata": {
        "id": "IwrHDmk6a7Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "train_seq = pad_sequences(X_train, maxlen=100) #문장 최대 길이 = 단어 100개\n",
        "print(train_seq.shape)\n",
        "\n",
        "# padding=\"pre\" -> 앞에서부터 자르고, 앞부분부터 패딩 (중요한 내용은 대부분 뒤에 포진함)\n",
        "# turncating = \"pre\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5VFvZ8wv7Ny",
        "outputId": "cbb203d4-d547-4dcb-eb2c-f9d7828eea47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[0])  #문장은 시작은 1임, 해당 글은 100보다 길어서 짤린 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paT5CrRBwK4m",
        "outputId": "d0eaaf1c-1ccd-4715-8df0-841b89ddcf18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 10   4  20   9   2 364 352   5  45   6   2   2  33 269   8   2 142   2\n",
            "   5   2  17  73  17 204   5   2  19  55   2   2  92  66 104  14  20  93\n",
            "  76   2 151  33   4  58  12 188   2 151  12 215  69 224 142  73 237   6\n",
            "   2   7   2   2 188   2 103  14  31  10  10 451   7   2   5   2  80  91\n",
            "   2  30   2  34  14  20 151  50  26 131  49   2  84  46  50  37  80  79\n",
            "   6   2  46   7  14  20  10  10 470 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0][-10:]) # 뒤쪽에 중요한 단어가 많이 나오므로, 뒤에서 단어 10개를 골라본 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JVxCtTLwNq-",
        "outputId": "93a5ee0d-cca5-4638-eb70-2556b951808a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 2, 46, 7, 14, 20, 10, 10, 470, 158]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_seq[5]) # 100보다 작다, 앞부분은 0으로 패딩"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srzs0_C9wRdV",
        "outputId": "fae23324-7a4d-4152-a151-44d85d470158"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0   0   1   2 195  19  49   2   2 190   4   2 352   2 183  10\n",
            "  10  13  82  79   4   2  36  71 269   8   2  25  19  49   7   4   2   2\n",
            "   2   2   2  10  10  48  25  40   2  11   2   2  40   2   2   5   4   2\n",
            "   2  95  14 238  56 129   2  10  10  21   2  94 364 352   2   2  11 190\n",
            "  24 484   2   7  94 205 405  10  10  87   2  34  49   2   7   2   2   2\n",
            "   2   2 290   2  46  48  64  18   4   2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_seq = pad_sequences(X_val, maxlen=100)\n",
        "val_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiwsJzxW0mFy",
        "outputId": "def47907-d3ca-4ff3-d9d6-88a60d21bf84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#순환 신경망 모델 만들기"
      ],
      "metadata": {
        "id": "ACZ-cB4DxRWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.Sequential()\n",
        "# model.add(keras.layers.SimpleRNN(8, input_shape=(100,500))) # 리뷰데이터 길이 = 100, 어휘사전의 크기 = 500\n",
        "# model.add(keras.layers.Dense(1, activation='sigmoid')) # 이진 분류는 뉴런 1개로도 표시 가능(양성, 음성 확률)"
      ],
      "metadata": {
        "id": "JwsyPB-7wrxQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_oh = keras.utils.to_categorical(train_seq) # one-hot encoding\n",
        "print(train_oh.shape) \n",
        "\n",
        "# 20000개 , 100 -> 문장의 길이(max-length), 500 -> 단어 길이 개수(원핫인코딩을 해서 500배가 된 것임, 가장 큰 단점)\n",
        "# 각각 어떤 것을 나타내는지 잘 이해하기!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BF6FY3J0XvE",
        "outputId": "89e9a2e6-1418-46ad-8a84-91487c402217"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_oh[0][0][:12]) # 첫번째 리뷰, 첫번째 단어, 해당 단어의 인덱스(500개 중 12개까지)"
      ],
      "metadata": {
        "id": "qsxdcal1gEQI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_oh[0,1,:12]"
      ],
      "metadata": {
        "id": "KbNdc6uM5x_R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_oh[0,99,:12] #하나의 샘플에 99개의 정보가 존재한다"
      ],
      "metadata": {
        "id": "0K6-7_s551of"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_oh = keras.utils.to_categorical(val_seq)\n",
        "val_oh.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiGK1qfW0frw",
        "outputId": "a2d47685-75b5-44dd-e5f2-089e4a4dcba1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 100, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary() # 마지막 timestep의 은닉 상태 = 뉴런의 개수\n",
        "\n",
        "# 숙제 : 왜 Trainable params가 4081개인가?\n",
        "# 뉴런 8개 500(차원의 원 핫 인코딩 배열)*8(개 뉴런과 연결)=4,000\n",
        "# 은닉상태 순환층 8(은닉상태크기) * 8(뉴런개수) = 64 가중치 + 편향 8개\n",
        "# 4,072\n",
        "# + Dense 층 9 (가중치8+편향1) = Dense(fuction='sigmoid', input_shape=(8,))\n",
        "# = 4,081"
      ],
      "metadata": {
        "id": "EA1Aij67zcBr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#순환 신경망 훈련하기"
      ],
      "metadata": {
        "id": "1iGhHPWCzj-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "# model.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn-model.h5')\n",
        "# early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "# history = model.fit(train_oh, y_train, epochs=100, batch_size=64, validation_data=(val_oh, y_val), callbacks=[checkpoint_cb, early_stopping_cb])\n",
        "\n",
        "# batch_size default 32 -> 늘릴수록 가중치의 안정성 증가(단, CPU 성능이 좋아야 함)\n",
        "# 우리는 64까지 늘렸다는 것이 특징!"
      ],
      "metadata": {
        "id": "E-lkMzKbzh-2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.xlabel('epoch')\n",
        "# plt.ylabel('loss')\n",
        "# plt.legend(['train','val'])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "zvXWLtTU0tCC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential()\n",
        "\n",
        "model2.add(keras.layers.SimpleRNN(8, return_sequences=True, dropout=0.3, input_shape=(100,500)))\n",
        "model2.add(keras.layers.SimpleRNN(8, dropout=0.3))\n",
        "model2.add(keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "BS-nfXMR4aaq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd-aqfj93RZc",
        "outputId": "bbd17b24-6919-4bbb-d0b0-645965459e4b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 100, 8)            4072      \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 8)                 136       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,217\n",
            "Trainable params: 4,217\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model2.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-simplernn2-model.h5')\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "history = model2.fit(train_oh, y_train, epochs=100, batch_size=64, validation_data=(val_oh, y_val), callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "mlyPrlsJc2il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G0Bi5kqfc4zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#단어 임베딩 사용하기"
      ],
      "metadata": {
        "id": "B3yLfqubCBJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding의 장점\n",
        "# 1. 메모리를 절약할 수 있다\n",
        "# 2. 유사도 사용하므로 학습 시, 학습의 효과가 더 좋아짐\n",
        "\n",
        "model3 = keras.Sequential()\n",
        "\n",
        "model3.add(keras.layers.Embedding(500, 16, input_length=100, name='embedding')) # 500 = 어휘 사전의 크기, 16 = 임베딩 단어 벡터의 크기(500이던 공간을 16개 공간으로 줄이기)\n",
        "model3.add(keras.layers.SimpleRNN(8, return_sequences=True, name='rnn_1'))\n",
        "model3.add(keras.layers.SimpleRNN(8, name='rnn_2'))\n",
        "model3.add(keras.layers.Dense(1, activation='sigmoid', name='output'))"
      ],
      "metadata": {
        "id": "DlVdZ04BByZn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32XtwcHmC47K",
        "outputId": "a0e9fc53-e671-4879-a403-c4afcefee1e4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           8000      \n",
            "                                                                 \n",
            " rnn_1 (SimpleRNN)           (None, 100, 8)            200       \n",
            "                                                                 \n",
            " rnn_2 (SimpleRNN)           (None, 8)                 136       \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,345\n",
            "Trainable params: 8,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop(learning_rate=1e-4)\n",
        "model3.compile(optimizer=rmsprop, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-embedding-model.tf') # 확장자 h5py overwrite dataset -> tf로 변경\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
        "history = model3.fit(train_seq, y_train, epochs=100, batch_size=64, validation_data=(val_seq, y_val), callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "id": "shwC3xtCdHBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train','val'])\n",
        "plt.show()\n",
        "\n",
        "# dropout 30%씩 해서 validation 결과가 더 낮게 나옴..underfit"
      ],
      "metadata": {
        "id": "UJElbVW0dINf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}